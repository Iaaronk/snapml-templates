{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w9APTDMy1TiO"
   },
   "source": [
    "## Introduction\n",
    "Optical Character Recognition (OCR) is a critical component in Computer Vision and Artificial Intelligence. Its applications span a variety of sectors, including document digitization, automated data entry, and license plate recognition. Unlike typical image processing tasks, OCR identifies, extracts, and digitizes written or printed characters from images or documents. This technology bridges the gap between the physical text world and the digital realm, allowing computers to understand and utilize written text within images.\n",
    "\n",
    "In this guide, we are going to show you how to run training of a powerful OCR model Paddle-OCR. You can read more about PaddleOCR in their official repo [here](https://github.com/PaddlePaddle/PaddleOCR)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DO9ql69B2oHj"
   },
   "source": [
    "## Prerequisite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjfBSy892yLS"
   },
   "source": [
    "If you are running this notebook in Google Colab, before starting to run the code, remember to choose GPU in Runtime:\n",
    "\n",
    "`(Runtime --> Change Runtime Type --> Hardware accelerator --> GPU)`\n",
    "\n",
    "We can validate this by running the `nvidia-smi` command, which will show helpful info like GPU driver/maximum CUDA version, GPUs' power and memory usage and current processes, etc.\n",
    "\n",
    "To get your current CUDA version, you can use `nvcc --version`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 621,
     "status": "ok",
     "timestamp": 1690375970057,
     "user": {
      "displayName": "Pavel Semkin",
      "userId": "04453955975692038114"
     },
     "user_tz": -180
    },
    "id": "NB71ra0z2pYo",
    "outputId": "bd9cdd45-0a91-48f1-e2cb-493b7765053b"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1690375970057,
     "user": {
      "displayName": "Pavel Semkin",
      "userId": "04453955975692038114"
     },
     "user_tz": -180
    },
    "id": "zwGe4u6c6Fvn",
    "outputId": "0e658bd8-4700-4f33-e272-c481bc2166a4"
   },
   "outputs": [],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ktf3w-B424rJ"
   },
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VRHBd1IC3MaW"
   },
   "source": [
    "First, we must install the PaddlePaddle framework to run the authors' training procedure. You can find the official installation instructions [here](https://www.paddlepaddle.org.cn/documentation/docs/en/install/index_en.html).\n",
    "\n",
    "There are pre-built pip packages for the following CUDA versions:\n",
    "\n",
    "- CUDA toolkit 10.2\n",
    "- CUDA toolkit 11.2\n",
    "- CUDA toolkit 11.6\n",
    "- CUDA toolkit 11.7\n",
    "\n",
    "If any matches your setup, you can install it using pip. In our case, we have CUDA 11.7 installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5914,
     "status": "ok",
     "timestamp": 1690375975970,
     "user": {
      "displayName": "Pavel Semkin",
      "userId": "04453955975692038114"
     },
     "user_tz": -180
    },
    "id": "X3W31z1L3hGS",
    "outputId": "ea274bb2-db8e-42a4-db39-0448148685d9"
   },
   "outputs": [],
   "source": [
    "# Uncomment line that matches your setup\n",
    "\n",
    "# CUDA 10.2\n",
    "# !python3 -m pip install paddlepaddle-gpu==2.4.2 -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "\n",
    "# CUDA 11.2\n",
    "# !python3 -m pip install paddlepaddle-gpu==2.4.2.post112 -f https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html\n",
    "\n",
    "# CUDA 11.6\n",
    "# !python3 -m pip install paddlepaddle-gpu==2.4.2.post116 -f https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html\n",
    "\n",
    "# CUDA 11.7\n",
    "!python3 -m pip install paddlepaddle-gpu==2.5.2.post117 -f https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DiZ1wN-D5T-y"
   },
   "source": [
    "In another case, you need to build in from the source. Please, refer to [the installation guide](https://www.paddlepaddle.org.cn/documentation/docs/en/install/index_en.html). Also, you can try to use the latter versions of the Paddle framework, but we didn't test them.\n",
    "\n",
    "Once `paddle` package is installed, we can clone the PaddleOCR repository and install all necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8160,
     "status": "ok",
     "timestamp": 1690375984127,
     "user": {
      "displayName": "Pavel Semkin",
      "userId": "04453955975692038114"
     },
     "user_tz": -180
    },
    "id": "Qbfk-jTM7TCN",
    "outputId": "2b29bbac-cad7-49fc-fd71-b0bded106682"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/PaddlePaddle/PaddleOCR.git\n",
    "!cd PaddleOCR && pip install -r requirements.txt\n",
    "!pip install protobuf~=3.20 gdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FIOoMw5g904i"
   },
   "source": [
    "## Training\n",
    "\n",
    "The PaddleOCR pipeline consists of several stages. There are several versions of models available. In our case, we used detection version 3 and recognition version 1.\n",
    "\n",
    "### Data Preparation\n",
    "\n",
    "#### Detection\n",
    "\n",
    "The detection model was trained using the ICDAR2015 dataset; we've prepared it and stored it in a necessary format; it can be found [here](https://drive.google.com/file/d/1YvNp1HAfUGI5ao17zzuPR5ai2R14NrNf).\n",
    "\n",
    "#### Recognition\n",
    "The model training config stored in the PaddleOCR repository suggests fine-tuning the recognition model using ICDAR2015 too; a subset prepared for recognition training can be found [here](https://drive.google.com/file/d/1YvNp1HAfUGI5ao17zzuPR5ai2R14NrNf).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38546,
     "status": "ok",
     "timestamp": 1690376022668,
     "user": {
      "displayName": "Pavel Semkin",
      "userId": "04453955975692038114"
     },
     "user_tz": -180
    },
    "id": "7ntTYmby0QYp",
    "outputId": "4492af35-dbbc-4e54-9203-55edfad2238e"
   },
   "outputs": [],
   "source": [
    "%cd PaddleOCR\n",
    "!gdown 1YvNp1HAfUGI5ao17zzuPR5ai2R14NrNf && unzip -q detection_recognition_train_data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLvo3vMV0QYp"
   },
   "source": [
    "### Detection Training\n",
    "\n",
    "Detection version 3 requires a multi-step teaching procedure. First of all, we need to train a teacher model. Let's begin with downloading the pre-trained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8333,
     "status": "ok",
     "timestamp": 1690376030999,
     "user": {
      "displayName": "Pavel Semkin",
      "userId": "04453955975692038114"
     },
     "user_tz": -180
    },
    "id": "usVNAt_m-u8O",
    "outputId": "8f11b8ce-c98e-4812-b49c-48d5b9356d92"
   },
   "outputs": [],
   "source": [
    "!mkdir ./pretrain_models\n",
    "# Download the pretrained model of ResNet50_vd and\n",
    "!wget -P ./pretrain_models/ https://paddleocr.bj.bcebos.com/pretrained/ResNet50_vd_ssld_pretrained.pdparams\n",
    "\n",
    "# Download the pre-trained model of MobileNetV3\n",
    "!wget -P ./pretrain_models/ https://paddleocr.bj.bcebos.com/pretrained/MobileNetV3_large_x0_5_pretrained.pdparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4VRrZqukCXPI"
   },
   "source": [
    "Now we can train the teacher model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 438,
     "status": "ok",
     "timestamp": 1690377590911,
     "user": {
      "displayName": "Pavel Semkin",
      "userId": "04453955975692038114"
     },
     "user_tz": -180
    },
    "id": "d39XL1vPCdq0",
    "outputId": "ac1973fe-2ce2-4f45-8eca-5b4497d97bf2"
   },
   "outputs": [],
   "source": [
    "# Single GPU training\n",
    "# You can pass Global.eval_batch_step to control the evaluation frequency\n",
    "!python3 tools/train.py -c configs/det/ch_PP-OCRv3/ch_PP-OCRv3_det_dml.yml \\\n",
    "    -o Architecture.Models.Student.pretrained=./pretrain_models/ResNet50_vd_ssld_pretrained \\\n",
    "       Architecture.Models.Student2.pretrained=./pretrain_models/ResNet50_vd_ssld_pretrained \\\n",
    "       Global.save_model_dir=./output/detection_teacher \\\n",
    "       Global.print_batch_step=20 \\\n",
    "       Train.loader.batch_size_per_card=2 # You can adjust the batch size based on your GPU VRAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dkNLO64oClMp"
   },
   "source": [
    "After the training is finished, we need to extract the student parameters, and we can train the lightweight student model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1863,
     "status": "ok",
     "timestamp": 1690376828293,
     "user": {
      "displayName": "Pavel Semkin",
      "userId": "04453955975692038114"
     },
     "user_tz": -180
    },
    "id": "HMna4ozb0QYp"
   },
   "outputs": [],
   "source": [
    "import paddle\n",
    "# load pretrained model\n",
    "all_params = paddle.load(\"output/detection_teacher/best_accuracy.pdparams\")\n",
    "# View the keys of the weight parameter\n",
    "# print(all_params.keys())\n",
    "# model weight extraction\n",
    "s_params = {key[len(\"Student.\"):]: all_params[key] for key in all_params if \"Student.\" in key}\n",
    "# View the keys of the model weight parameters\n",
    "# print(s_params.keys())\n",
    "# save\n",
    "paddle.save(s_params, \"./pretrain_models/dml_teacher.pdparams\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WuoSr5lrCnd3",
    "outputId": "4d87fbb8-a26d-4fe0-fbc1-e36f0446ad36"
   },
   "outputs": [],
   "source": [
    "# Single card training\n",
    "# You can pass Global.eval_batch_step to control the evaluation frequency\n",
    "!python3 tools/train.py -c configs/det/ch_PP-OCRv3/ch_PP-OCRv3_det_cml.yml \\\n",
    "    -o Architecture.Models.Student.pretrained=./pretrain_models/MobileNetV3_large_x0_5_pretrained \\\n",
    "       Architecture.Models.Student2.pretrained=./pretrain_models/MobileNetV3_large_x0_5_pretrained \\\n",
    "       Architecture.Models.Teacher.pretrained=./pretrain_models/dml_teacher \\\n",
    "       Global.save_model_dir=./output/detection_lightweight \\\n",
    "       Train.loader.batch_size_per_card=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_Hoa26PCtU8"
   },
   "source": [
    "The model saved during training is in the output directory. You can evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 235629,
     "status": "ok",
     "timestamp": 1690377472653,
     "user": {
      "displayName": "Pavel Semkin",
      "userId": "04453955975692038114"
     },
     "user_tz": -180
    },
    "id": "Ux1_jMrFCv2A",
    "outputId": "4a3f6d0c-77d6-45df-acb6-98465813d423"
   },
   "outputs": [],
   "source": [
    "!python3 tools/eval.py -c configs/det/ch_PP-OCRv3/ch_PP-OCRv3_det_cml.yml -o Global.checkpoints=./output/detection_lightweight/best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x01ZJfTUCyWD"
   },
   "source": [
    "best_accuracy checkpoint contains three model parameters, corresponding to Student, Student2, and Teacher, in the configuration file. The method to extract the Student parameter is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3594,
     "status": "ok",
     "timestamp": 1690377499036,
     "user": {
      "displayName": "Pavel Semkin",
      "userId": "04453955975692038114"
     },
     "user_tz": -180
    },
    "id": "GRVsLFz4C5m7"
   },
   "outputs": [],
   "source": [
    "import paddle\n",
    "# load pretrained model\n",
    "all_params = paddle.load(\"output/detection_lightweight/best_accuracy.pdparams\")\n",
    "# View the keys of the weight parameter\n",
    "# print(all_params.keys())\n",
    "# model weight extraction\n",
    "s_params = {key[len(\"Student.\"):]: all_params[key] for key in all_params if \"Student.\" in key}\n",
    "# View the keys of the model weight parameters\n",
    "# print(s_params.keys())\n",
    "# save\n",
    "paddle.save(s_params, \"./pretrain_models/detection_v3_cml.pdparams\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "boglrk0gDDcM"
   },
   "source": [
    "### Recognition Training\n",
    "\n",
    "Recognition version 1 can be trained in a single-step procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwOdAt5oDxRq"
   },
   "source": [
    "Note that the difference between Chinese and English models is in training data only, so we correct some paths in config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gvaveVaxDzws",
    "outputId": "c6953157-b194-4888-afc8-9466625acb57"
   },
   "outputs": [],
   "source": [
    "!python3 tools/train.py -c configs/rec/ch_ppocr_v2.0/rec_chinese_lite_train_v2.0.yml \\\n",
    "                        -o Global.save_model_dir=./output/rec_en_v1 \\\n",
    "                           Global.infer_image=./doc/imgs_words/en/word_1.jpg \\\n",
    "                           Global.character_dict_path=./ppocr/utils/en_dict.txt \\\n",
    "                           Global.save_res_path=./output/rec_en_v1/predicts_en_common_v2.0.txt \\\n",
    "                           Train.dataset.data_dir=./train_data/ic15_data/ \\\n",
    "                           Train.dataset.label_file_list=./train_data/ic15_data/rec_gt_train.txt \\\n",
    "                           Eval.dataset.data_dir=./train_data/ic15_data/ \\\n",
    "                           Eval.dataset.label_file_list=./train_data/ic15_data/rec_gt_test.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwSvlnlf0QY0"
   },
   "source": [
    "## Conclusion\n",
    "Once your models are trained, you can follow the instructions from our [inference](https://colab.research.google.com/drive/1Rru8y0CKrBo1_Wj6RV0hqyrur-eX91vy?authuser=0#scrollTo=YHrilj060QYr) notebook to convert them into ONNX format and run testing. Make sure to follow [the instructions](https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_en/inference_en.md#1-convert-training-model-to-inference-model) to save inference state checkpoint, which is required for testing."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
